# VLM Integration Summary - æ•´åˆå®Œæˆå ±å‘Š

> **å®Œæˆæ—¥æœŸ**: 2026-02-06  
> **ç‰ˆæœ¬**: v2.2 (VLM Integration)  
> **ç‹€æ…‹**: âœ… æ•´åˆæ¸¬è©¦é€šé

---

## ğŸ“‹ æ•´åˆæ¦‚è¦

æˆåŠŸå°‡ **VLM (è¦–è¦ºèªè¨€æ¨¡å‹)** åŠŸèƒ½æ•´åˆåˆ° NKUST è£½ç¨‹è¾¨è­˜ç³»çµ±ï¼Œå¯¦ç¾ AI é©…å‹•çš„å·¥ç¨‹åœ–è£½ç¨‹åˆ†æã€‚

### æ ¸å¿ƒåŠŸèƒ½

- âœ… VLM å®¢æˆ¶ç«¯ (èˆ‡ LM Studio / OpenAI API é€šè¨Š)
- âœ… è£½ç¨‹è¾¨è­˜æç¤ºè©ç³»çµ±
- âœ… å¤šæ¨¡æ…‹èåˆæ±ºç­–å¼•æ“ (å‚³çµ±ç‰¹å¾µ + VLM)
- âœ… Streamlit UI æ•´åˆ (VLM é–‹é—œ + çµæœé¡¯ç¤º)
- âœ… å®Œæ•´æ¸¬è©¦å¥—ä»¶

---

## ğŸ—ï¸ æ¶æ§‹è®Šæ›´

### 1. è³‡æ–™çµæ§‹ (`schema.py`)

**æ–°å¢ VLM åˆ†ææ¬„ä½åˆ° `ExtractedFeatures`**:

```python
@dataclass
class ExtractedFeatures:
    ...
    vlm_analysis: Optional[Dict[str, Any]] = None  # NEW: VLM åˆ†æçµæœ
    ...
```

**VLM åˆ†æçµæœæ ¼å¼**:
```python
{
    "shape_description": "L å‹éˆ‘é‡‘é›¶ä»¶",
    "overall_complexity": "ä¸­ç­‰",
    "detected_features": {
        "geometry": ["æŠ˜å½ç·š", "å­”æ´"],
        "symbols": ["ç„Šæ¥ç¬¦è™Ÿ"],
        "text_annotations": ["SPCC", "t1.0"],
        "material_info": "SPCC"
    },
    "suggested_process_ids": ["C01", "D01", "E01"],
    "confidence_scores": {
        "C01": 0.95,
        "D01": 0.90,
        "E01": 0.85
    },
    "reasoning": "åˆ¤æ–·ä¾æ“š...",
    "process_sequence": ["C01", "D01", "E01"]
}
```

**Bug ä¿®å¾©**:
- ä¿®æ­£ `to_dict()` æ–¹æ³•å° `None` geometry çš„è™•ç†

---

### 2. è£½ç¨‹ç®¡ç·š (`pipeline.py`)

**æ–°å¢ VLM åŠŸèƒ½é–‹é—œ**:

```python
class ManufacturingPipeline:
    def __init__(
        self,
        ...
        use_vlm: bool = False,  # NEW: VLM é–‹é—œ
        ...
    ):
        ...
        # VLM å®¢æˆ¶ç«¯åˆå§‹åŒ– (å„ªé›…è™•ç†æœå‹™ä¸å¯ç”¨)
        if use_vlm:
            self.vlm_client = VLMClient()
            if self.vlm_client.is_available():
                self.vlm_prompt_template = EngineeringPrompts.get_process_recognition_prompt()
            else:
                self.vlm_client = None
                self.use_vlm = False
```

**VLM ç‰¹å¾µæå–**:

```python
def _extract_features(self, image, ..., image_path=None):
    ...
    # VLM åˆ†æ
    if self.use_vlm and self.vlm_client:
        vlm_result = self.vlm_client.analyze_image(
            image_path=image_path or image,
            prompt=self.vlm_prompt_template.user_prompt,
            response_format="json"
        )
        vlm_analysis = vlm_result
    ...
```

---

### 3. æ±ºç­–å¼•æ“ (`decision/engine_v2.py`)

**VLM è©•åˆ†æ•´åˆ**:

```python
def _score_all_processes(self, features, frequency_filter):
    # å–å¾— VLM å»ºè­°
    vlm_suggestions = {}
    if features.vlm_analysis:
        suggested_ids = features.vlm_analysis.get("suggested_process_ids", [])
        confidence_scores = features.vlm_analysis.get("confidence_scores", {})
        vlm_suggestions = {pid: confidence_scores.get(pid, 0.7) for pid in suggested_ids}
    
    # å‹•æ…‹èª¿æ•´æ¬Šé‡
    if vlm_score > 0:
        weights = {
            "text": 0.25,
            "symbol": 0.20,
            "geometry": 0.15,
            "vlm": 0.40  # VLM æœ‰å»ºè­°æ™‚æ¬Šé‡æé«˜
        }
    
    # èåˆè©•åˆ†
    final_score = (
        text_score * weights["text"] +
        symbol_score * weights["symbol"] +
        geometry_score * weights["geometry"] +
        vlm_score * weights["vlm"]
    )
```

**VLM è­‰æ“šæ”¶é›†**:

```python
def _collect_evidence(self, ..., vlm_score=0.0):
    evidence = []
    
    # VLM è­‰æ“š (æœ€é«˜å„ªå…ˆç´š)
    if vlm_score > 0.3 and features.vlm_analysis:
        vlm_reasoning = features.vlm_analysis.get("reasoning", "")
        evidence.append(f"[VLM åˆ†æ] {vlm_reasoning[:200]}")
        
        detected_features = features.vlm_analysis.get("detected_features", {})
        if detected_features.get("geometry"):
            evidence.append(f"[VLM å¹¾ä½•] {', '.join(detected_features['geometry'][:3])}")
    ...
```

---

### 4. Streamlit UI (`aov_app.py`)

**VLM åŠŸèƒ½é–‹é—œ**:

```python
with st.expander("ç‰¹å¾µæå–é¸é …", expanded=True):
    ...
    use_vlm = st.checkbox(
        "ğŸ¤– VLM è¦–è¦ºèªè¨€æ¨¡å‹åˆ†æ (å¯¦é©—åŠŸèƒ½)",
        value=False,
        help="ä½¿ç”¨ AI è¦–è¦ºèªè¨€æ¨¡å‹é€²è¡Œè£½ç¨‹è¾¨è­˜ (éœ€è¦ LM Studio é‹è¡Œä¸­)"
    )
    
    # VLM ç‹€æ…‹æª¢æŸ¥
    if use_vlm:
        vlm_test = VLMClient()
        if vlm_test.is_available():
            st.success("âœ… VLM æœå‹™å·²é€£æ¥ (LM Studio)")
        else:
            st.warning("âš ï¸ VLM æœå‹™æœªé‹è¡Œ - è«‹ç¢ºèª LM Studio å·²å•Ÿå‹•")
```

**VLM çµæœé¡¯ç¤º**:

```python
# VLM åˆ†æçµæœ
if result.features.vlm_analysis:
    st.markdown("**ğŸ¤– VLM è¦–è¦ºèªè¨€æ¨¡å‹åˆ†æ:**")
    vlm = result.features.vlm_analysis
    
    # å½¢ç‹€æè¿°
    if vlm.get("shape_description"):
        st.caption(f"å½¢ç‹€: {vlm['shape_description']}")
    
    # å»ºè­°è£½ç¨‹
    if vlm.get("suggested_process_ids"):
        st.caption(f"VLM å»ºè­°è£½ç¨‹: {', '.join(vlm['suggested_process_ids'][:5])}")
    
    # æ¨ç†ä¾æ“š
    if vlm.get("reasoning"):
        with st.expander("æŸ¥çœ‹ VLM æ¨ç†ä¾æ“š"):
            st.text(vlm["reasoning"])
```

---

## ğŸ§ª æ¸¬è©¦é©—è­‰

### æ•´åˆæ¸¬è©¦è…³æœ¬ (`test_vlm_integration.py`)

**æ¸¬è©¦ç¯„åœ**:
1. âœ… æ¨¡çµ„åŒ¯å…¥æ¸¬è©¦ (5/5 é€šé)
2. âœ… VLM æœå‹™å¯ç”¨æ€§æª¢æŸ¥
3. âœ… Pipeline åˆå§‹åŒ– (VLM é–‹é—œ)
4. âœ… ExtractedFeatures Schema é©—è­‰
5. âœ… DecisionEngineV2 VLM è©•åˆ†æ¸¬è©¦
6. âœ… ç«¯åˆ°ç«¯é æ¸¬æµç¨‹

**æ¸¬è©¦çµæœ**:

```
âœ… æ‰€æœ‰æ ¸å¿ƒæ•´åˆæ¸¬è©¦é€šé

åŠŸèƒ½ç‹€æ…‹:
  - VLM å®¢æˆ¶ç«¯: å¯ç”¨
  - Pipeline VLM é–‹é—œ: æ­£å¸¸
  - Schema VLM æ¬„ä½: æ­£å¸¸
  - Engine VLM è©•åˆ†: æ­£å¸¸
```

---

## ğŸ“ æª”æ¡ˆè®Šæ›´æ¸…å–®

### ä¿®æ”¹æª”æ¡ˆ (4 å€‹)

| æª”æ¡ˆ | è®Šæ›´å…§å®¹ | ç‹€æ…‹ |
|------|---------|------|
| `app/manufacturing/schema.py` | æ–°å¢ `vlm_analysis` æ¬„ä½, ä¿®æ­£ `to_dict()` | âœ… |
| `app/manufacturing/pipeline.py` | æ–°å¢ `use_vlm` åƒæ•¸, VLM å®¢æˆ¶ç«¯åˆå§‹åŒ–, VLM ç‰¹å¾µæå– | âœ… |
| `app/manufacturing/decision/engine_v2.py` | VLM è©•åˆ†æ•´åˆ, å‹•æ…‹æ¬Šé‡èª¿æ•´, VLM è­‰æ“šæ”¶é›† | âœ… |
| `aov_app.py` | VLM åŠŸèƒ½é–‹é—œ, æœå‹™ç‹€æ…‹æª¢æŸ¥, VLM çµæœé¡¯ç¤º | âœ… |

### æ–°å¢æª”æ¡ˆ (å·²åœ¨å‰æ¬¡ commit)

| æª”æ¡ˆ | ç”¨é€” | Commit |
|------|------|--------|
| `app/manufacturing/extractors/vlm_client.py` | VLM å®¢æˆ¶ç«¯ | 10853b3 |
| `app/manufacturing/prompts.py` | æç¤ºè©ç³»çµ± | 17d2231 |
| `VLM_FEATURE_GUIDE.md` | VLM ä½¿ç”¨æŒ‡å— | 10853b3 |
| `PROMPTS_GUIDE.md` | æç¤ºè©æŒ‡å— | 17d2231 |
| `test_vlm_integration.py` | æ•´åˆæ¸¬è©¦è…³æœ¬ | (æœ¬æ¬¡) |

---

## ğŸ¯ ä½¿ç”¨æ–¹å¼

### 1. å•Ÿå‹• LM Studio

1. ä¸‹è¼‰ä¸¦å®‰è£ [LM Studio](https://lmstudio.ai/)
2. è¼‰å…¥æ”¯æ´è¦–è¦ºçš„æ¨¡å‹ (æ¨è–¦: **LLaVA 1.6 7B**)
3. å•Ÿå‹•æœ¬åœ°ä¼ºæœå™¨ (é è¨­ `http://localhost:1234`)

### 2. ä½¿ç”¨ Python API

```python
from app.manufacturing import ManufacturingPipeline

# åˆå§‹åŒ–ç®¡ç·š (å•Ÿç”¨ VLM)
pipeline = ManufacturingPipeline(
    use_ocr=False,
    use_geometry=True,
    use_symbols=True,
    use_vlm=True  # å•Ÿç”¨ VLM
)

# è¾¨è­˜å·¥ç¨‹åœ–
result = pipeline.recognize("drawing.jpg", top_n=5)

# æª¢æŸ¥ VLM åˆ†æçµæœ
if result.features.vlm_analysis:
    print("VLM å»ºè­°è£½ç¨‹:", result.features.vlm_analysis["suggested_process_ids"])
```

### 3. ä½¿ç”¨ Streamlit UI

```bash
streamlit run aov_app.py
```

1. ä¸Šå‚³å·¥ç¨‹åœ–ç´™
2. åœ¨ã€Œç‰¹å¾µæå–é¸é …ã€å‹¾é¸ã€ŒğŸ¤– VLM è¦–è¦ºèªè¨€æ¨¡å‹åˆ†æã€
3. ç¢ºèª VLM æœå‹™å·²é€£æ¥ (ç¶ è‰²å‹¾é¸)
4. é»æ“Šã€Œé–‹å§‹è¾¨è­˜è£½ç¨‹ã€

---

## ğŸ“Š æ•ˆèƒ½è©•ä¼°

### å¤šæ¨¡æ…‹èåˆæ¬Šé‡

**VLM æœªå•Ÿç”¨æ™‚** (å‚³çµ±æ¨¡å¼):
```python
{
    "text": 0.40,      # OCR æ–‡å­—
    "symbol": 0.30,    # ç¬¦è™Ÿè¾¨è­˜
    "geometry": 0.20,  # å¹¾ä½•ç‰¹å¾µ
    "visual": 0.10     # è¦–è¦ºåµŒå…¥
}
```

**VLM å•Ÿç”¨æ™‚** (VLM æœ‰å»ºè­°):
```python
{
    "text": 0.25,      # OCR æ–‡å­—
    "symbol": 0.20,    # ç¬¦è™Ÿè¾¨è­˜
    "geometry": 0.15,  # å¹¾ä½•ç‰¹å¾µ
    "vlm": 0.40        # VLM åˆ†æ (æœ€é«˜æ¬Šé‡)
}
```

### VLM å„ªå‹¢

1. **å…¨å±€ç†è§£**: VLM èƒ½ç†è§£æ•´é«”é›¶ä»¶å½¢ç‹€å’Œè£½ç¨‹é‚è¼¯
2. **èªç¾©æ¨ç†**: ä¸åƒ…è­˜åˆ¥ç‰¹å¾µ,é‚„èƒ½æ¨ç†è£½ç¨‹ä¾è³´é—œä¿‚
3. **å°‘æ¨£æœ¬å­¸ç¿’**: ä¸éœ€è¦å¤§é‡è¨“ç·´æ•¸æ“šå³å¯è­˜åˆ¥æ–°è£½ç¨‹
4. **è‡ªç„¶èªè¨€è§£é‡‹**: æä¾›å¯è®€çš„æ¨ç†ä¾æ“š

---

## âš ï¸ æ³¨æ„äº‹é …

### é™åˆ¶

1. **éœ€è¦ LM Studio**: VLM åŠŸèƒ½éœ€è¦æœ¬åœ°é‹è¡Œ LM Studio
2. **æ¨¡å‹å¤§å°**: è¦–è¦ºæ¨¡å‹é€šå¸¸è¼ƒå¤§ (7B - 13B åƒæ•¸)
3. **æ¨ç†é€Ÿåº¦**: VLM æ¨ç†æ¯”å‚³çµ±ç‰¹å¾µæå–æ…¢ (3-10 ç§’)
4. **GPU è¨˜æ†¶é«”**: å»ºè­°è‡³å°‘ 8GB VRAM

### å»ºè­°

- **æ¸¬è©¦ç’°å¢ƒ**: å…ˆç”¨ `test_vlm_integration.py` é©—è­‰æ•´åˆ
- **ç”Ÿç”¢ç’°å¢ƒ**: å¯é¸æ“‡æ€§å•Ÿç”¨ VLM (é è¨­é—œé–‰)
- **æ•ˆèƒ½å„ªåŒ–**: å°æ–¼æ‰¹æ¬¡è™•ç†,å¯ä½¿ç”¨å¿«å–æ©Ÿåˆ¶
- **æ¨¡å‹é¸æ“‡**: LLaVA 1.6 7B ç‚ºé€Ÿåº¦èˆ‡æº–ç¢ºåº¦çš„å¹³è¡¡é»

---

## ğŸ”„ å¾ŒçºŒå·¥ä½œ

### é«˜å„ªå…ˆç´š

- [ ] ç«¯åˆ°ç«¯æ¸¬è©¦ (å¯¦éš›å·¥ç¨‹åœ– + LM Studio)
- [ ] VLM Prompt å„ªåŒ– (æ ¹æ“šå¯¦éš›çµæœèª¿æ•´)
- [ ] README.md æ›´æ–° (VLM åŠŸèƒ½èªªæ˜)

### ä¸­å„ªå…ˆç´š

- [ ] VLM å¿«å–æ©Ÿåˆ¶ (é¿å…é‡è¤‡æ¨ç†)
- [ ] VLM æ‰¹æ¬¡è™•ç† (æå‡ååé‡)
- [ ] éŒ¯èª¤é‡è©¦æ©Ÿåˆ¶ (æå‡ç©©å®šæ€§)

### ä½å„ªå…ˆç´š

- [ ] VLM æ¨¡å‹åˆ‡æ› (æ”¯æ´å¤šç¨®è¦–è¦ºæ¨¡å‹)
- [ ] VLM æ•ˆèƒ½æŒ‡æ¨™æ”¶é›† (æ¨ç†æ™‚é–“ã€æº–ç¢ºåº¦)
- [ ] VLM çµæœå¿«å– (æª”æ¡ˆ hash â†’ VLM çµæœ)

---

## ğŸ“š ç›¸é—œæ–‡ä»¶

- **VLM åŠŸèƒ½æŒ‡å—**: `VLM_FEATURE_GUIDE.md`
- **æç¤ºè©æŒ‡å—**: `PROMPTS_GUIDE.md`
- **ç³»çµ±æ¶æ§‹**: `MANUFACTURING.md`
- **ä½¿ç”¨æ‰‹å†Š**: `README.md`

---

## ğŸ‰ ç¸½çµ

âœ… **VLM æ•´åˆå·²å®Œæˆä¸¦é€šéæ¸¬è©¦**

- **4 å€‹æ ¸å¿ƒæª”æ¡ˆä¿®æ”¹**: Schema, Pipeline, DecisionEngine, UI
- **1 å€‹æ–°æ¸¬è©¦è…³æœ¬**: `test_vlm_integration.py`
- **6 é …æ•´åˆæ¸¬è©¦**: å…¨éƒ¨é€šé
- **å‘å¾Œç›¸å®¹**: VLM é è¨­é—œé–‰,ä¸å½±éŸ¿ç¾æœ‰åŠŸèƒ½

**ä¸‹ä¸€æ­¥**: å¯¦éš›å·¥ç¨‹åœ–æ¸¬è©¦ + æ•ˆèƒ½å„ªåŒ– + æ–‡æª”å®Œå–„

---

**NKUST è¦–è¦ºå¯¦é©—å®¤** Â© 2026
